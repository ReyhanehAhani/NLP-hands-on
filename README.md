## Implementing different ways of tokenization algorithms
## Overview

This repository contains a series of Jupyter notebooks, as part of the coursework for Natural Language Learning. These notebooks aim to explore various facets of NLP through a structured set of questions, spanning tokenization techniques, analysis of tokenization models, N-grams, and sentiment analysis.

## Content

The coursework is divided into four main questions, each focusing on different aspects of NLP and employing Python libraries like `re` for regular expressions and other text processing techniques.

### Question 1: Tokenization Techniques

- **Part 1:** Introduction to basic tokenization using word boundaries and character sequences.
- **Part 2:** Advanced tokenization, addressing issues with special characters and abbreviations.
- **Part 3:** Enhancements to the tokenizer to support hashtags and other composite tokens.

### Question 2: Analysis of Tokenization Models

- **Part 1:** Examination of BERT and GPT tokenization strategies, including WordPiece and Byte Pair Encoding (BPE).
- **Part 2:** Comparison of sub-word tokenization methods, highlighting their advantages in handling unseen words and reducing vocabulary size.
- **Part 3:** Practical implementation and comparison of WordPiece and BPE tokenizations, demonstrating their distinct approaches to breaking down text.

### Question 3: N-Grams and Text Coherence

- **Parts 1-5:** Exploration of N-grams, from bi-grams to higher-order grams, and their impact on modeling text coherence. This section includes practical exercises to generate text using N-grams and analyses the effect of N-gram order on text generation quality.

### Question 4: Sentiment Analysis

- **Part 1:** Development of a basic sentiment analysis model to classify text.
- **Part 2:** Evaluation of the model's performance and discussion on improving accuracy through feature engineering and model complexity.

## Libraries and Tools Used

- `re`: For regular expressions, essential in pattern matching and text manipulation.
- Other Python standard libraries such as `collections` and `string` for data manipulation and processing.
